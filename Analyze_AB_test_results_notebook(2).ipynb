{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze A/B Test Results\n",
    "\n",
    "## Table of Contents\n",
    "- [Introduction](#intro)\n",
    "- [Part I - Probability](#probability)\n",
    "- [Part II - A/B Test](#ab_test)\n",
    "- [Part III - Regression](#regression)\n",
    "\n",
    "\n",
    "<a id='intro'></a>\n",
    "### Introduction\n",
    "\n",
    "For this project, I will be working to understand the results of an A/B test run by an e-commerce website.  My goal is to work through this notebook to help the company understand if they should implement the new page, keep the old page, or perhaps run the experiment longer to make their decision.\n",
    "\n",
    "<a id='probability'></a>\n",
    "#### Part I - Probability\n",
    "\n",
    "To get started, I'll import the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#We are setting the seed to assure you get the same answers on quizzes as we set up\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset\n",
    "df = pd.read_csv('ab_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294478"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0] #show the number of rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The number of unique users in the dataset.\n",
    "df['user_id'].nunique() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. The proportion of users converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11965919355605512"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the proportion of users converted.\n",
    "df.query('converted == 1').count()[0]/df.shape[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "e. The number of times the `new_page` and `treatment` don't match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3893"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate The number of times the new_page and treatment don't match\n",
    "len(df[(df['landing_page'] == \"new_page\") != (df['group'] == \"treatment\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id         0\n",
       "timestamp       0\n",
       "group           0\n",
       "landing_page    0\n",
       "converted       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` For the rows that cannot be sure if this row truly received the new or old page. So,I'll drop the rows where **treatment** does not match with **new_page** or **control** does not match with **old_page** and craete a new dataset that **treatment** match with **new_page** and **control** match with **old_page** and Store new dataframe in **df2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows where treatment does not match with new_page or control does not match with old_page\n",
    "df2 = df.drop(df[(df['landing_page'] == \"new_page\") != (df['group'] == \"treatment\")].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58603</th>\n",
       "      <td>658832</td>\n",
       "      <td>2017-01-20 10:14:50.645427</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279432</th>\n",
       "      <td>664550</td>\n",
       "      <td>2017-01-15 02:26:27.289080</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280293</th>\n",
       "      <td>903210</td>\n",
       "      <td>2017-01-05 15:21:23.468704</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171171</th>\n",
       "      <td>929643</td>\n",
       "      <td>2017-01-23 02:44:48.941980</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271143</th>\n",
       "      <td>646011</td>\n",
       "      <td>2017-01-23 18:30:28.979953</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117529</th>\n",
       "      <td>719066</td>\n",
       "      <td>2017-01-06 18:00:28.164284</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216817</th>\n",
       "      <td>758595</td>\n",
       "      <td>2017-01-08 02:27:42.996983</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232784</th>\n",
       "      <td>898844</td>\n",
       "      <td>2017-01-14 06:47:13.090195</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73745</th>\n",
       "      <td>770528</td>\n",
       "      <td>2017-01-16 21:54:48.167171</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211873</th>\n",
       "      <td>674964</td>\n",
       "      <td>2017-01-15 23:22:36.749906</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                   timestamp      group landing_page  converted\n",
       "58603    658832  2017-01-20 10:14:50.645427  treatment     new_page          0\n",
       "279432   664550  2017-01-15 02:26:27.289080  treatment     new_page          0\n",
       "280293   903210  2017-01-05 15:21:23.468704    control     old_page          0\n",
       "171171   929643  2017-01-23 02:44:48.941980  treatment     new_page          0\n",
       "271143   646011  2017-01-23 18:30:28.979953  treatment     new_page          0\n",
       "117529   719066  2017-01-06 18:00:28.164284    control     old_page          0\n",
       "216817   758595  2017-01-08 02:27:42.996983    control     old_page          0\n",
       "232784   898844  2017-01-14 06:47:13.090195  treatment     new_page          0\n",
       "73745    770528  2017-01-16 21:54:48.167171  treatment     new_page          0\n",
       "211873   674964  2017-01-15 23:22:36.749906    control     old_page          0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the new datframe\n",
    "df2.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double Check all of the correct rows were removed - this should be 0\n",
    "df2[((df2['group'] == 'treatment') != (df2['landing_page'] == 'new_page'))].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate how many unique user_ids are in df2\n",
    "df2['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "b. There is one **user_id** repeated in **df2**.  What is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "773192    2\n",
       "630732    1\n",
       "811737    1\n",
       "797392    1\n",
       "795345    1\n",
       "         ..\n",
       "650647    1\n",
       "648598    1\n",
       "654741    1\n",
       "652692    1\n",
       "630836    1\n",
       "Name: user_id, Length: 290584, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for if there are users id repeated in df2\n",
    "df2.user_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-09 05:37:58.781806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "1899   773192  2017-01-09 05:37:58.781806  treatment     new_page          0\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the row information for the repeat user_id\n",
    "df2.loc[df2['user_id'] == 773192] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove one of the rows with a duplicate user_id\n",
    "df2 = df2.drop(df.index[2893]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-09 05:37:58.781806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "1899   773192  2017-01-09 05:37:58.781806  treatment     new_page          0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #check the row that was repeating\n",
    "df2.loc[df2['user_id'] == 773192]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4. What is the probability of an individual converting regardless of the page they receive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the probability of an individual converting regardless of the page they receive\n",
    "df2['converted'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Given that an individual was in the `control` group, what is the probability they converted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1203863045004612"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute converted rate for control group\n",
    "converted_old = df2.query('group == \"control\"')['converted'].mean()\n",
    "converted_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Given that an individual was in the `treatment` group, what is the probability they converted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11880806551510564"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute converted rate for treatment group\n",
    "converted_new = df2.query('group == \"treatment\"')['converted'].mean() \n",
    "converted_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. What is the probability that an individual received the new page?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000619442226688"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the probability that an individual received the new page\n",
    "df2.query('landing_page == \"new_page\"').count()[0]/df2.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I will use these results from probablity part, and explain in A/B Test part below whether there is sufficient evidence to conclude that the new treatment page leads to more conversions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ab_test'></a>\n",
    "### Part II - A/B Test\n",
    "\n",
    "\n",
    "`1.` For now, I'll assume that the old page is better unless the new page proves to be definitely better at a Type I error rate of 5%,so the null and alternative hypotheses would be:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**H0**: $p_{new}$ - $p_{old}$ = 0\n",
    "\n",
    "**H1**: $p_{new}$ - $p_{old}$ > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumed under the null hypothesis, $p_{new}$ and $p_{old}$ both have \"true\" success rates equal to the **converted** success rate regardless of page - that is $p_{new}$ and $p_{old}$ are equal. Furthermore, assume they are equal to the **converted** rate in **ab_data.csv** regardless of the page. <br><br>\n",
    "\n",
    "I'll use a sample size for each page equal to the ones in **ab_data.csv**.  <br><br>\n",
    "\n",
    "then I'll Perform the sampling distribution for the difference in **converted** between the two pages over 10,000 iterations of calculating an estimate from the null.  <br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. What is the **conversion rate** for $p_{new}$ under the null? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute conversion rate for 𝑝𝑛𝑒𝑤 under the null\n",
    "p_new = df2.query('converted == 1')['user_id'].nunique()/(df2.user_id.nunique())\n",
    "p_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. What is the **conversion rate** for $p_{old}$ under the null? <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conversion rate for 𝑝𝑜𝑙𝑑 under the null\n",
    "#under the null hypothesis,  𝑝𝑛𝑒𝑤 and 𝑝𝑜𝑙𝑑 are equal\n",
    "p_old = p_new\n",
    "p_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. What is $n_{new}$, the number of individuals in the treatment group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145310"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the number of individuals in the treatment group as n_new\n",
    "n_new = df2.query('group == \"treatment\"')['user_id'].count()\n",
    "n_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. What is $n_{old}$, the number of individuals in the control group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145274"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute the number of individuals in the control group as n_old\n",
    "n_old = df2.query(\" group == 'control'\")['user_id'].count()\n",
    "n_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Simulate $n_{new}$ transactions with a conversion rate of $p_{new}$ under the null.  Store these $n_{new}$ 1's and 0's in **new_page_converted**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulate 𝑛𝑛𝑒𝑤 transactions with a conversion rate of 𝑝𝑛𝑒𝑤 under the null\n",
    "new_page_converted = np.random.binomial(1, p_new, n_new)\n",
    "new_page_converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Simulate $n_{old}$ transactions with a conversion rate of $p_{old}$ under the null.  Store these $n_{old}$ 1's and 0's in **old_page_converted**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Simulate 𝑛𝑛𝑒𝑤 transactions with a conversion rate of 𝑝old under the null\n",
    "old_page_converted = np.random.binomial(1,p_old, n_old)\n",
    "old_page_converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. Find $p_{new}$ - $p_{old}$ for your simulated values from part (e) and (f)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0008101496178952727"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate 𝑝𝑛𝑒𝑤 - 𝑝𝑜𝑙𝑑\n",
    "new_page_converted.mean() - old_page_converted.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. Create 10,000 $p_{new}$ - $p_{old}$ values using the same simulation process you used in parts (a) through (g) above. Store all 10,000 values in a NumPy array called **p_diffs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.07824674e-04, -8.89952780e-04, -2.24352096e-05, ...,\n",
       "        3.93035168e-05, -3.87488161e-04,  1.28620760e-04])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#simulate 𝑝𝑛𝑒𝑤 - 𝑝𝑜𝑙𝑑 transaction for 10,000 time\n",
    "p_diffs = []\n",
    "\n",
    "new_page_converted  = np.random.binomial(n_new, p_new, 10000)/n_new\n",
    "old_page_converted  = np.random.binomial(n_old,p_old, 10000)/n_old\n",
    "p_diffs = new_page_converted  - old_page_converted\n",
    "p_diffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Plot a histogram of the **p_diffs**.  Does this plot look like what you expected?  Use the matching problem in the classroom to assure you fully understand what was computed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert to numpy array\n",
    "plt.hist(p_diffs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j. What proportion of the **p_diffs** are greater than the actual difference observed in **ab_data.csv**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1972\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compute differences in observation\n",
    "obs_diff = converted_new - converted_old\n",
    "\n",
    "# Compute p-value\n",
    "low_prob = (p_diffs < obs_diff).mean()\n",
    "high_prob = (p_diffs.mean() + (p_diffs.mean() - obs_diff) < p_diffs).mean()\n",
    "\n",
    "# Plot observed statistic with the null distibution\n",
    "plt.hist(p_diffs);\n",
    "plt.axvline(obs_diff, color='orange');\n",
    "plt.axvline(p_diffs.mean() + (p_diffs.mean() - obs_diff), color='orange');\n",
    "\n",
    "p_val = low_prob + high_prob            \n",
    "print(p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> if the p-value less than type I error=0.05. it would indicate a low probability of assuming that the null hypothesis is true. I got the p-value for both directions because the alternative hypothesis is two sided and that mean have both negative value or positive can applay.\n",
    "\n",
    "\n",
    "> the p-value is above 0.05 which means I fail to reject the null hypothsis so I have evidence that old page equal in converted rate with the new page.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l. I would also use a built-in to calculate the number of conversions for each page, as well as the number of individuals who received each page. where `n_old` and `n_new` refer the the number of rows associated with the old page and new pages, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute number of conversion for old page and new page\n",
    "convert_old = df2.query('landing_page == \"old_page\"')['converted'].sum()\n",
    "convert_new = df2.query('landing_page == \"new_page\"')['converted'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m. Now use `stats.proportions_ztest` to compute your test statistic and p-value.  [Here](https://docs.w3cub.com/statsmodels/generated/statsmodels.stats.proportion.proportions_ztest/) is a helpful link on using the built in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the computed z test statistic is 1.3109241984234394\n",
      "the p-value is  0.18988337448195103\n"
     ]
    }
   ],
   "source": [
    "#using stats.proportions_ztest to compute Z-test and p-value\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "number_of_success = np.array([convert_old,convert_new])\n",
    "total_sample_size = np.array([n_old,n_new])\n",
    "\n",
    "(stat,pval) = proportions_ztest(number_of_success, total_sample_size, alternative='two-sided')\n",
    "print(\"the computed z test statistic is\", stat)\n",
    "print(\"the p-value is \",pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.904902082204761"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute the significance of z-score\n",
    "from scipy.stats import norm\n",
    "\n",
    "norm.cdf(1.31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6448536269514722"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute crtical values at 95% confidence level\n",
    "norm.ppf(1-.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> the z-score I've computed means the difference between the test(the difference between conversion rates) and the null hypothesis is 1.31\n",
    "standard deviation above the mean. with type I error = 0.05 and confidence level 95% the critical values are 1.96, which means z score less than the critical value so I havn't evidence to reject the null hypothesis and that mean the old page is equal the new page in converasion rates\n",
    "\n",
    ">the p-value here is 0.189 and it is greater than alpha so I fail to reject the null hypothesis which is mean the difference between the means is not statistically significant and the old page is equal the new page in converasion rates\n",
    "\n",
    "> this p-value I've got from z test equal the previous p-value = 0.1942\n",
    " so the z-test appears to agree with the previous findings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regression'></a>\n",
    "### Part III - A regression approach\n",
    "\n",
    "`1.` In this final part,I will fit model is attempting to predict whether a user will convert depending on their received page.\n",
    "and see that if the result that achieved in the A/B test in Part II above can also be achieved by performing regression.<br><br> \n",
    "\n",
    "a. Since each row is either a conversion or no conversion,I would perform Logistic Regression in this case because the the response variable is categorical variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. So I'll use **statsmodels** to fit the logistic regression model to see if there is a significant difference in conversion based on which page a customer receives. However, I'll create in df2 a column for the intercept, and I'll create a dummy variable column for which page each user received that would be an **ab_page** column, which is 1 when an individual receives the **treatment** and 0 if **control** to predict whether or not an individual converts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>old_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  ab_page  old_page  \n",
       "0          1        0         1  \n",
       "1          1        0         1  \n",
       "2          1        1         0  \n",
       "3          1        1         0  \n",
       "4          1        0         1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a column for the intercept\n",
    "df2['intercept']= 1\n",
    "\n",
    "#create dummy variable column for which page each user received\n",
    "df2[['ab_page','old_page']] = pd.get_dummies(df2['landing_page'])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop old page and make it basline \n",
    "df2 = df2.drop('old_page', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230621</th>\n",
       "      <td>790255</td>\n",
       "      <td>2017-01-07 23:42:14.487651</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                   timestamp    group landing_page  converted  \\\n",
       "230621   790255  2017-01-07 23:42:14.487651  control     old_page          0   \n",
       "\n",
       "        intercept  ab_page  \n",
       "230621          1        0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366118\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>converted</td>          <td>AIC:</td>        <td>212780.3502</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-03-06 19:51</td>       <td>BIC:</td>        <td>212801.5095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>290584</td>       <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>1</td>            <td>LL-Null:</td>      <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>290582</td>        <td>LLR p-value:</td>      <td>0.18988</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>      <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-1.9888</td>  <td>0.0081</td>  <td>-246.6690</td> <td>0.0000</td> <td>-2.0046</td> <td>-1.9730</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>-0.0150</td>  <td>0.0114</td>   <td>-1.3109</td>  <td>0.1899</td> <td>-0.0374</td> <td>0.0074</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.000      \n",
       "Dependent Variable: converted        AIC:              212780.3502\n",
       "Date:               2021-03-06 19:51 BIC:              212801.5095\n",
       "No. Observations:   290584           Log-Likelihood:   -1.0639e+05\n",
       "Df Model:           1                LL-Null:          -1.0639e+05\n",
       "Df Residuals:       290582           LLR p-value:      0.18988    \n",
       "Converged:          1.0000           Scale:            1.0000     \n",
       "No. Iterations:     6.0000                                        \n",
       "-------------------------------------------------------------------\n",
       "              Coef.   Std.Err.      z      P>|z|    [0.025   0.975]\n",
       "-------------------------------------------------------------------\n",
       "intercept    -1.9888    0.0081  -246.6690  0.0000  -2.0046  -1.9730\n",
       "ab_page      -0.0150    0.0114    -1.3109  0.1899  -0.0374   0.0074\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a logistic model and fit it with the dummy variable and intercept \n",
    "log_model = sm.Logit(df2['converted'], df2[['intercept','ab_page']])\n",
    "results = log_model.fit()\n",
    "# show the summary of the model \n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is attempting to predict whether a user will convert depending on the page that customer received. The null hypothesis is that when ab_page = 1, converted = 0; the alternative hypothesis is that when ab_page = 1, converted is more likely to be 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**the p-value associated with ab_page is 0.1899 that mean p-value > alpha which means I'll fail to reject the null hypothesis \n",
    "which is similar to the value I found it in a/b testing but slightly smaller, where we still reject to fail the null hypothesis,**.\n",
    "\n",
    ">  from this model interpret that for every one not recieved the new page , the converted is 1.015 times as likely to happen and this not has much impact on increasing the conversion rates so it will be cost for not more icreasing in conversion rates\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, it does not appear that the treatment or control page has much impact on whether a user converts. Therefore, it is probably a good idea to add an effect based on which country a user lives in.to see if  whether effected in predicting conversion.\n",
    "\n",
    "thus I'll create dummy variables for these country columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It is important to be when selecting factors to make sure the factors are not in and of themselves collinear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. Now along with testing if the conversion rate changes for different pages, also add an effect based on which country a user lives in. I will read in the **countries.csv** dataset and merge together the datasets on the appropriate rows. \n",
    "\n",
    "so I'll explore if the country had an impact on conversion or not ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>834778</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>928468</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>822059</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>711597</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>710616</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id country\n",
       "0   834778      UK\n",
       "1   928468      US\n",
       "2   822059      UK\n",
       "3   711597      UK\n",
       "4   710616      UK"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the data of country a user live in\n",
    "country = pd.read_csv('countries.csv')\n",
    "country.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US    203619\n",
       "UK     72466\n",
       "CA     14499\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the unique values in country column\n",
    "country.country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  ab_page country  \n",
       "0          1        0      US  \n",
       "1          1        0      US  \n",
       "2          1        1      US  \n",
       "3          1        1      US  \n",
       "4          1        0      US  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merage the country dataframe with the orignal dataframe\n",
    "df3 = df2.merge(country, on='user_id', how='left')\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>country</th>\n",
       "      <th>US</th>\n",
       "      <th>UK</th>\n",
       "      <th>CA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  ab_page country  US  UK  CA  \n",
       "0          1        0      US   0   0   1  \n",
       "1          1        0      US   0   0   1  \n",
       "2          1        1      US   0   0   1  \n",
       "3          1        1      US   0   0   1  \n",
       "4          1        0      US   0   0   1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make dummies varaible for countries\n",
    "df3[['US','UK', 'CA']]= pd.get_dummies(df3['country'])\n",
    "\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366113\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>converted</td>          <td>AIC:</td>        <td>212781.1253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-03-06 19:51</td>       <td>BIC:</td>        <td>212823.4439</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>290584</td>       <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>3</td>            <td>LL-Null:</td>      <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>290580</td>        <td>LLR p-value:</td>      <td>0.17599</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-2.0300</td>  <td>0.0266</td>  <td>-76.2488</td> <td>0.0000</td> <td>-2.0822</td> <td>-1.9778</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>-0.0149</td>  <td>0.0114</td>   <td>-1.3069</td> <td>0.1912</td> <td>-0.0374</td> <td>0.0075</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA</th>        <td>0.0408</td>   <td>0.0269</td>   <td>1.5161</td>  <td>0.1295</td> <td>-0.0119</td> <td>0.0934</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>0.0506</td>   <td>0.0284</td>   <td>1.7835</td>  <td>0.0745</td> <td>-0.0050</td> <td>0.1063</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.000      \n",
       "Dependent Variable: converted        AIC:              212781.1253\n",
       "Date:               2021-03-06 19:51 BIC:              212823.4439\n",
       "No. Observations:   290584           Log-Likelihood:   -1.0639e+05\n",
       "Df Model:           3                LL-Null:          -1.0639e+05\n",
       "Df Residuals:       290580           LLR p-value:      0.17599    \n",
       "Converged:          1.0000           Scale:            1.0000     \n",
       "No. Iterations:     6.0000                                        \n",
       "-------------------------------------------------------------------\n",
       "               Coef.   Std.Err.     z      P>|z|    [0.025   0.975]\n",
       "-------------------------------------------------------------------\n",
       "intercept     -2.0300    0.0266  -76.2488  0.0000  -2.0822  -1.9778\n",
       "ab_page       -0.0149    0.0114   -1.3069  0.1912  -0.0374   0.0075\n",
       "CA             0.0408    0.0269    1.5161  0.1295  -0.0119   0.0934\n",
       "UK             0.0506    0.0284    1.7835  0.0745  -0.0050   0.1063\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make logistic model to predict the converted using CA and old page as baseline\n",
    "\n",
    "log_model_2= sm.Logit(df3['converted'], df3[['intercept','ab_page' , 'CA','UK']])\n",
    "results= log_model_2.fit()\n",
    "results.summary2()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the p-values above, it also does not appear as though country has a significant impact on conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. Though I have now looked at the individual factors of country and page on conversion, I would now like to look at an interaction between page and country to see if there significant effects on conversion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an interaction variables between page and country to see if there significant effects on conversion\n",
    "df3['CA_page'] = df3['CA']*df3['ab_page']\n",
    "df3['UK_page'] = df3['UK']*df3['ab_page']\n",
    "df3['US_page'] = df3['US']*df3['ab_page']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366117\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>converted</td>          <td>AIC:</td>        <td>212781.7674</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-03-06 19:51</td>       <td>BIC:</td>        <td>212813.5064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>290584</td>       <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>2</td>            <td>LL-Null:</td>      <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>290581</td>        <td>LLR p-value:</td>      <td>0.31643</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>      <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-1.9926</td>  <td>0.0079</td>  <td>-252.9104</td> <td>0.0000</td> <td>-2.0081</td> <td>-1.9772</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA_page</th>   <td>-0.0144</td>  <td>0.0125</td>   <td>-1.1548</td>  <td>0.2482</td> <td>-0.0389</td> <td>0.0101</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK_page</th>   <td>0.0112</td>   <td>0.0179</td>   <td>0.6256</td>   <td>0.5316</td> <td>-0.0240</td> <td>0.0464</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.000      \n",
       "Dependent Variable: converted        AIC:              212781.7674\n",
       "Date:               2021-03-06 19:51 BIC:              212813.5064\n",
       "No. Observations:   290584           Log-Likelihood:   -1.0639e+05\n",
       "Df Model:           2                LL-Null:          -1.0639e+05\n",
       "Df Residuals:       290581           LLR p-value:      0.31643    \n",
       "Converged:          1.0000           Scale:            1.0000     \n",
       "No. Iterations:     6.0000                                        \n",
       "-------------------------------------------------------------------\n",
       "              Coef.   Std.Err.      z      P>|z|    [0.025   0.975]\n",
       "-------------------------------------------------------------------\n",
       "intercept    -1.9926    0.0079  -252.9104  0.0000  -2.0081  -1.9772\n",
       "CA_page      -0.0144    0.0125    -1.1548  0.2482  -0.0389   0.0101\n",
       "UK_page       0.0112    0.0179     0.6256  0.5316  -0.0240   0.0464\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make logistic model to predict the converted using an interaction variables between page and country \n",
    "\n",
    "log_model_3= sm.Logit(df3['converted'], df3[['intercept','CA_page','UK_page']])\n",
    "results= log_model_3.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept    0.136338\n",
       "CA_page      0.985679\n",
       "UK_page      1.011292\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exponentiated the CV to inteprete the result\n",
    "np.exp(results.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Interpreting the Logistic model Result:\n",
    ">since all values of p-values not statistically significant so we don't have enough evidence to reject the null hypothesis based on A/B testing. As a result, there is no reason to switch to the new page, when the old one performs just as well.\n",
    "\n",
    ">Whereas all reuslts not significant, that's mean the page and country dataset are not a good fit to predict converted rate So I will train and test the data set to prevent or minimize overfitting.    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df3['converted']\n",
    "x = df3[['ab_page','CA_page','UK_page']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size =0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51112,     0],\n",
       "       [ 7005,     0]], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_mod = LogisticRegression()\n",
    "log_mod.fit(x_train, y_train)\n",
    "preds = log_mod.predict(x_test)\n",
    "confusion_matrix(y_test, preds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8794672815183165"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**since the precision value and recall value equal to zero thats mean I have misclassifing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'Analyze_ab_test_results_notebook.ipynb'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
