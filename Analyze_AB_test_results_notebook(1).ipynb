{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze A/B Test Results\n",
    "\n",
    "## Table of Contents\n",
    "- [Introduction](#intro)\n",
    "- [Part I - Probability](#probability)\n",
    "- [Part II - A/B Test](#ab_test)\n",
    "- [Part III - Regression](#regression)\n",
    "\n",
    "\n",
    "<a id='intro'></a>\n",
    "### Introduction\n",
    "\n",
    "For this project, I will be working to understand the results of an A/B test run by an e-commerce website.  My goal is to work through this notebook to help the company understand if they should implement the new page, keep the old page, or perhaps run the experiment longer to make their decision.\n",
    "\n",
    "<a id='probability'></a>\n",
    "#### Part I - Probability\n",
    "\n",
    "To get started, I'll import the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#We are setting the seed to assure you get the same answers on quizzes as we set up\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset\n",
    "df = pd.read_csv('ab_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294478"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0] #show the number of rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The number of unique users in the dataset.\n",
    "df['user_id'].nunique() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. The proportion of users converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11965919355605512"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the proportion of users converted.\n",
    "df.query('converted == 1').count()[0]/df.shape[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "e. The number of times the `new_page` and `treatment` don't match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3893"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate The number of times the new_page and treatment don't match\n",
    "len(df[(df['landing_page'] == \"new_page\") != (df['group'] == \"treatment\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id         0\n",
       "timestamp       0\n",
       "group           0\n",
       "landing_page    0\n",
       "converted       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` For the rows that cannot be sure if this row truly received the new or old page. So,I'll drop the rows where **treatment** does not match with **new_page** or **control** does not match with **old_page** and craete a new dataset that **treatment** match with **new_page** and **control** match with **old_page** and Store new dataframe in **df2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows where treatment does not match with new_page or control does not match with old_page\n",
    "df2 = df.drop(df[(df['landing_page'] == \"new_page\") != (df['group'] == \"treatment\")].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>223261</th>\n",
       "      <td>912431</td>\n",
       "      <td>2017-01-24 12:26:24.513120</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257858</th>\n",
       "      <td>805569</td>\n",
       "      <td>2017-01-05 05:53:32.091323</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160528</th>\n",
       "      <td>767314</td>\n",
       "      <td>2017-01-20 02:37:03.937101</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36219</th>\n",
       "      <td>632229</td>\n",
       "      <td>2017-01-21 16:10:03.566497</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99367</th>\n",
       "      <td>703771</td>\n",
       "      <td>2017-01-12 20:34:26.812313</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31109</th>\n",
       "      <td>796844</td>\n",
       "      <td>2017-01-23 18:10:10.239803</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135556</th>\n",
       "      <td>689331</td>\n",
       "      <td>2017-01-13 16:50:55.346216</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206063</th>\n",
       "      <td>805098</td>\n",
       "      <td>2017-01-06 09:50:31.340127</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130988</th>\n",
       "      <td>816951</td>\n",
       "      <td>2017-01-15 18:12:31.618593</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5626</th>\n",
       "      <td>644529</td>\n",
       "      <td>2017-01-15 03:19:59.661833</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                   timestamp      group landing_page  converted\n",
       "223261   912431  2017-01-24 12:26:24.513120    control     old_page          0\n",
       "257858   805569  2017-01-05 05:53:32.091323  treatment     new_page          0\n",
       "160528   767314  2017-01-20 02:37:03.937101  treatment     new_page          0\n",
       "36219    632229  2017-01-21 16:10:03.566497    control     old_page          0\n",
       "99367    703771  2017-01-12 20:34:26.812313    control     old_page          1\n",
       "31109    796844  2017-01-23 18:10:10.239803    control     old_page          0\n",
       "135556   689331  2017-01-13 16:50:55.346216    control     old_page          0\n",
       "206063   805098  2017-01-06 09:50:31.340127  treatment     new_page          0\n",
       "130988   816951  2017-01-15 18:12:31.618593  treatment     new_page          0\n",
       "5626     644529  2017-01-15 03:19:59.661833  treatment     new_page          0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the new datframe\n",
    "df2.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double Check all of the correct rows were removed - this should be 0\n",
    "df2[((df2['group'] == 'treatment') != (df2['landing_page'] == 'new_page'))].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate how many unique user_ids are in df2\n",
    "df2['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "b. There is one **user_id** repeated in **df2**.  What is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "773192    2\n",
       "630732    1\n",
       "811737    1\n",
       "797392    1\n",
       "795345    1\n",
       "         ..\n",
       "650647    1\n",
       "648598    1\n",
       "654741    1\n",
       "652692    1\n",
       "630836    1\n",
       "Name: user_id, Length: 290584, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for if there are users id repeated in df2\n",
    "df2.user_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-09 05:37:58.781806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "1899   773192  2017-01-09 05:37:58.781806  treatment     new_page          0\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the row information for the repeat user_id\n",
    "df2.loc[df2['user_id'] == 773192] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove one of the rows with a duplicate user_id\n",
    "df2 = df2.drop(df.index[2893]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-09 05:37:58.781806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "1899   773192  2017-01-09 05:37:58.781806  treatment     new_page          0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #check the row that was repeating\n",
    "df2.loc[df2['user_id'] == 773192]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4. What is the probability of an individual converting regardless of the page they receive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the probability of an individual converting regardless of the page they receive\n",
    "df2['converted'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Given that an individual was in the `control` group, what is the probability they converted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1203863045004612"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute converted rate for control group\n",
    "converted_old = df2.query('group == \"control\"')['converted'].mean()\n",
    "converted_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Given that an individual was in the `treatment` group, what is the probability they converted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11880806551510564"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute converted rate for treatment group\n",
    "converted_new = df2.query('group == \"treatment\"')['converted'].mean() \n",
    "converted_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. What is the probability that an individual received the new page?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000619442226688"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the probability that an individual received the new page\n",
    "df2.query('landing_page == \"new_page\"').count()[0]/df2.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I will use these results from probablity part, and explain in A/B Test part below whether there is sufficient evidence to conclude that the new treatment page leads to more conversions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ab_test'></a>\n",
    "### Part II - A/B Test\n",
    "\n",
    "\n",
    "`1.` For now, I'll assume that the old page is better unless the new page proves to be definitely better at a Type I error rate of 5%,so the null and alternative hypotheses would be:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**H0**: $p_{new}$ - $p_{old}$ = 0\n",
    "\n",
    "**H1**: $p_{new}$ - $p_{old}$ > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumed under the null hypothesis, $p_{new}$ and $p_{old}$ both have \"true\" success rates equal to the **converted** success rate regardless of page - that is $p_{new}$ and $p_{old}$ are equal. Furthermore, assume they are equal to the **converted** rate in **ab_data.csv** regardless of the page. <br><br>\n",
    "\n",
    "I'll use a sample size for each page equal to the ones in **ab_data.csv**.  <br><br>\n",
    "\n",
    "then I'll Perform the sampling distribution for the difference in **converted** between the two pages over 10,000 iterations of calculating an estimate from the null.  <br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. What is the **conversion rate** for $p_{new}$ under the null? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute conversion rate for ùëùùëõùëíùë§ under the null\n",
    "p_new = df2.query('converted == 1')['user_id'].nunique()/(df2.user_id.nunique())\n",
    "p_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. What is the **conversion rate** for $p_{old}$ under the null? <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conversion rate for ùëùùëúùëôùëë under the null\n",
    "#under the null hypothesis,  ùëùùëõùëíùë§ and ùëùùëúùëôùëë are equal\n",
    "p_old = p_new\n",
    "p_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. What is $n_{new}$, the number of individuals in the treatment group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145310"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the number of individuals in the treatment group as n_new\n",
    "n_new = df2.query('group == \"treatment\"')['user_id'].count()\n",
    "n_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. What is $n_{old}$, the number of individuals in the control group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145274"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute the number of individuals in the control group as n_old\n",
    "n_old = df2.query(\" group == 'control'\")['user_id'].count()\n",
    "n_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Simulate $n_{new}$ transactions with a conversion rate of $p_{new}$ under the null.  Store these $n_{new}$ 1's and 0's in **new_page_converted**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulate ùëõùëõùëíùë§ transactions with a conversion rate of ùëùùëõùëíùë§ under the null\n",
    "new_page_converted = np.random.binomial(1, p_new, n_new)\n",
    "new_page_converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Simulate $n_{old}$ transactions with a conversion rate of $p_{old}$ under the null.  Store these $n_{old}$ 1's and 0's in **old_page_converted**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Simulate ùëõùëõùëíùë§ transactions with a conversion rate of ùëùold under the null\n",
    "old_page_converted = np.random.binomial(1,p_old, n_old)\n",
    "old_page_converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. Find $p_{new}$ - $p_{old}$ for your simulated values from part (e) and (f)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001080076451102363"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate ùëùùëõùëíùë§ - ùëùùëúùëôùëë\n",
    "new_page_converted.mean() - old_page_converted.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. Create 10,000 $p_{new}$ - $p_{old}$ values using the same simulation process you used in parts (a) through (g) above. Store all 10,000 values in a NumPy array called **p_diffs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00107876, -0.00145441,  0.00074843, ...,  0.00017691,\n",
       "       -0.00128217,  0.00012187])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#simulate ùëùùëõùëíùë§ - ùëùùëúùëôùëë transaction for 10,000 time\n",
    "p_diffs = []\n",
    "\n",
    "new_page_converted  = np.random.binomial(n_new, p_new, 10000)/n_new\n",
    "old_page_converted  = np.random.binomial(n_old,p_old, 10000)/n_old\n",
    "p_diffs = new_page_converted  - old_page_converted\n",
    "p_diffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Plot a histogram of the **p_diffs**.  Does this plot look like what you expected?  Use the matching problem in the classroom to assure you fully understand what was computed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQDklEQVR4nO3df6zddX3H8edroIypBFgLK223dqYmA5LhaCqJ/7gxpYFlrXEm9Q9pMpMqwUQTzVZ0ifpHE/xJQpwsNRJK4iRdlNAE2ERiYkxAvCBYCnZUqXJtB9f5h7hkLMX3/jjfxuPl3HvP/XHO6eXzfCQn53vf38/nfD/fD7evfvs533NIVSFJasPvTXoAkqTxMfQlqSGGviQ1xNCXpIYY+pLUkLMnPYCFrFmzpjZt2jTpYUjSqvLoo4/+oqrWzq6f8aG/adMmpqamJj0MSVpVkvx0UN3lHUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JasgZ/4lc6Uy1ae+9Ezv28Zuvm9ixtbp5pS9JDTH0Jakhhr4kNcQ1fa16k1xbl1Ybr/QlqSGGviQ1xNCXpIYY+pLUkAVDP8nGJN9O8nSSI0k+1NU/meTnSR7vHtf29bkpybEkR5Nc01e/Msnhbt+tSTKa05IkDTLM3TungI9U1WNJ3gA8muSBbt8tVfW5/sZJLgV2AZcBlwDfSvKmqnoZuA3YAzwM3AdsB+5fmVORJC1kwSv9qjpZVY912y8CTwPr5+myA7irql6qqmeBY8C2JOuA86rqoaoq4E5g53JPQJI0vEWt6SfZBLwZ+F5X+mCSHya5PckFXW098Fxft+mutr7bnl0fdJw9SaaSTM3MzCxmiJKkeQwd+kleD3wd+HBV/YreUs0bgSuAk8DnTzcd0L3mqb+yWLW/qrZW1da1a9cOO0RJ0gKGCv0kr6EX+F+tqm8AVNXzVfVyVf0G+DKwrWs+DWzs674BONHVNwyoS5LGZJi7dwJ8BXi6qr7QV1/X1+ydwJPd9iFgV5JzkmwGtgCPVNVJ4MUkV3WveT1wzwqdhyRpCMPcvfNW4L3A4SSPd7WPAe9JcgW9JZrjwPsBqupIkoPAU/Tu/Lmxu3MH4AbgDuBcenfteOeOJI3RgqFfVd9l8Hr8ffP02QfsG1CfAi5fzAAlSSvHT+RKUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0JekhiwY+kk2Jvl2kqeTHEnyoa5+YZIHkjzTPV/Q1+emJMeSHE1yTV/9yiSHu323JsloTkuSNMgwV/qngI9U1Z8BVwE3JrkU2As8WFVbgAe7n+n27QIuA7YDX0pyVvdatwF7gC3dY/sKnoskaQELhn5Vnayqx7rtF4GngfXADuBA1+wAsLPb3gHcVVUvVdWzwDFgW5J1wHlV9VBVFXBnXx9J0hgsak0/ySbgzcD3gIur6iT0/mIALuqarQee6+s23dXWd9uz64OOsyfJVJKpmZmZxQxRkjSPoUM/yeuBrwMfrqpfzdd0QK3mqb+yWLW/qrZW1da1a9cOO0RJ0gKGCv0kr6EX+F+tqm905ee7JRu65xe6+jSwsa/7BuBEV98woC5JGpNh7t4J8BXg6ar6Qt+uQ8Dubns3cE9ffVeSc5JspveG7SPdEtCLSa7qXvP6vj6SpDE4e4g2bwXeCxxO8nhX+xhwM3AwyfuAnwHvBqiqI0kOAk/Ru/Pnxqp6uet3A3AHcC5wf/eQJI3JgqFfVd9l8Ho8wNVz9NkH7BtQnwIuX8wAJUkrx0/kSlJDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXk7EkPQNLibdp770SOe/zm6yZyXK0cr/QlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDVkw9JPcnuSFJE/21T6Z5OdJHu8e1/btuynJsSRHk1zTV78yyeFu361JsvKnI0mazzCfyL0D+CJw56z6LVX1uf5CkkuBXcBlwCXAt5K8qapeBm4D9gAPA/cB24H7lzV6nTEm9QlRSYuz4JV+VX0H+OWQr7cDuKuqXqqqZ4FjwLYk64Dzquqhqip6f4HsXOKYJUlLtJw1/Q8m+WG3/HNBV1sPPNfXZrqrre+2Z9cHSrInyVSSqZmZmWUMUZLUb6mhfxvwRuAK4CTw+a4+aJ2+5qkPVFX7q2prVW1du3btEocoSZptSaFfVc9X1ctV9Rvgy8C2btc0sLGv6QbgRFffMKAuSRqjJYV+t0Z/2juB03f2HAJ2JTknyWZgC/BIVZ0EXkxyVXfXzvXAPcsYtyRpCRa8eyfJ14C3AWuSTAOfAN6W5Ap6SzTHgfcDVNWRJAeBp4BTwI3dnTsAN9C7E+hcenfteOeOJI3ZgqFfVe8ZUP7KPO33AfsG1KeAyxc1OknSivITuZLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0JakhC4Z+ktuTvJDkyb7ahUkeSPJM93xB376bkhxLcjTJNX31K5Mc7vbdmiQrfzqSpPkMc6V/B7B9Vm0v8GBVbQEe7H4myaXALuCyrs+XkpzV9bkN2ANs6R6zX1OSNGILhn5VfQf45azyDuBAt30A2NlXv6uqXqqqZ4FjwLYk64Dzquqhqirgzr4+kqQxWeqa/sVVdRKge76oq68HnutrN93V1nfbs+sDJdmTZCrJ1MzMzBKHKEmabaXfyB20Tl/z1Aeqqv1VtbWqtq5du3bFBidJrVtq6D/fLdnQPb/Q1aeBjX3tNgAnuvqGAXVJ0hgtNfQPAbu77d3APX31XUnOSbKZ3hu2j3RLQC8muaq7a+f6vj6SpDE5e6EGSb4GvA1Yk2Qa+ARwM3AwyfuAnwHvBqiqI0kOAk8Bp4Abq+rl7qVuoHcn0LnA/d1DkjRGC4Z+Vb1njl1Xz9F+H7BvQH0KuHxRo5MkrSg/kStJDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpy9qQHIGn12LT33okc9/jN103kuK9GXulLUkMMfUlqiKEvSQ1xTf9VZlJrrpJWB6/0Jakhhr4kNcTQl6SGLCv0kxxPcjjJ40mmutqFSR5I8kz3fEFf+5uSHEtyNMk1yx28JGlxVuJK/y+r6oqq2tr9vBd4sKq2AA92P5PkUmAXcBmwHfhSkrNW4PiSpCGNYnlnB3Cg2z4A7Oyr31VVL1XVs8AxYNsIji9JmsNyQ7+AbyZ5NMmernZxVZ0E6J4v6urrgef6+k53tVdIsifJVJKpmZmZZQ5RknTacu/Tf2tVnUhyEfBAkh/N0zYDajWoYVXtB/YDbN26dWAbSdLiLetKv6pOdM8vAHfTW655Psk6gO75ha75NLCxr/sG4MRyji9JWpwlh36S1yV5w+lt4B3Ak8AhYHfXbDdwT7d9CNiV5Jwkm4EtwCNLPb4kafGWs7xzMXB3ktOv869V9e9Jvg8cTPI+4GfAuwGq6kiSg8BTwCngxqp6eVmjlyQtypJDv6p+Avz5gPp/A1fP0WcfsG+px5QkLY+fyJWkhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkOW/D9Gl6Rx2bT33okd+/jN103s2KPglb4kNcTQl6SGuLwzApP8p6gkzccrfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktSQsYd+ku1JjiY5lmTvuI8vSS0b6336Sc4C/hl4OzANfD/Joap6ahTH8355Scs1qRwZ1dc/jPtKfxtwrKp+UlX/B9wF7BjzGCSpWeP+RO564Lm+n6eBt8xulGQPsKf78ddJjo5hbGuAX4zhOKuRczM/52duzs3c5p2bfHrZr/8ng4rjDv0MqNUrClX7gf2jH85vJZmqqq3jPOZq4dzMz/mZm3Mzt0nNzbiXd6aBjX0/bwBOjHkMktSscYf+94EtSTYneS2wCzg05jFIUrPGurxTVaeSfBD4D+As4PaqOjLOMcxjrMtJq4xzMz/nZ27OzdwmMjepesWSuiTpVcpP5EpSQwx9SWrIqz70k1yY5IEkz3TPF8zRbuDXQyzUP8kfJ/l1ko+O+lxW2qjmJsnbkzya5HD3/FfjOqflWuhrQtJza7f/h0n+YqG+w87zmW5Ec/PZJD/q2t+d5Pwxnc6KG8X89O3/aJJKsmbZA62qV/UD+Aywt9veC3x6QJuzgB8Dfwq8FngCuHSY/sDXgX8DPjrpcz1T5gZ4M3BJt3058PNJn+uQ8zHnufa1uRa4n95nTq4Cvrfc36HV8Bjh3LwDOLvb/vRqnJtRzk+3fyO9m19+CqxZ7lhf9Vf69L7m4UC3fQDYOaDNfF8PMWf/JDuBnwBnyh1IizWSuamqH1TV6c9fHAF+P8k5Kz76lTfM14TsAO6snoeB85OsW6DvMPN8phvJ3FTVN6vqVNf/YXqf3VmNRvW7A3AL8A8M+CDrUrQQ+hdX1UmA7vmiAW0GfT3E+vn6J3kd8I/Ap0Y07nEYydzM8i7gB1X10oqNenTmO9eF2ix3ns50o5qbfn9P70p4NRrJ/CT5W3r/Un5ipQY67q9hGIkk3wL+aMCujw/7EgNqC/2t+inglqr6dTKo+5lhQnNz+tiX0fsn+zuGPNakDXOuc7VZ8jytEiOdmyQfB04BX13S6CZvxecnyR/Q+3O6on9+XhWhX1V/Pde+JM8nWVdVJ7t/Sr0woNl8Xw8xV/+3AH+X5DPA+cBvkvxvVX1xueezkiY0NyTZANwNXF9VP172iYzHMF8TMleb187Td5h5PtONam5Ishv4G+Dq6haxV6FRzM8bgc3AE92F5QbgsSTbquq/ljzSSb8BMuoH8Fl+9020zwxocza9tfnN/PaNlMsW0f+TrM43ckcyN/T+EnwCeNekz3GR8zHnufa1uY7ffTPukZX4HTrTHyOcm+3AU8DaSZ/jmTg/s/ofZwXeyJ34ZI3hP8YfAg8Cz3TPF3b1S4D7+tpdC/wnvXfRP75Q/1nHWK2hP5K5Af4J+B/g8b7HRZM+3yHn5BXnCnwA+EC3HXr/I6AfA4eBrSvxO7QaHiOam2P01rNP/578y6TP80yan1mvf5wVCH2/hkGSGtLC3TuSpI6hL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhry/wr9/ZoRyHgBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert to numpy array\n",
    "plt.hist(p_diffs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j. What proportion of the **p_diffs** are greater than the actual difference observed in **ab_data.csv**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18830000000000002\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compute differences in observation\n",
    "obs_diff = converted_new - converted_old\n",
    "\n",
    "# Compute p-value\n",
    "low_prob = (p_diffs < obs_diff).mean()\n",
    "high_prob = (p_diffs.mean() + (p_diffs.mean() - obs_diff) < p_diffs).mean()\n",
    "\n",
    "# Plot observed statistic with the null distibution\n",
    "plt.hist(p_diffs);\n",
    "plt.axvline(obs_diff, color='orange');\n",
    "plt.axvline(p_diffs.mean() + (p_diffs.mean() - obs_diff), color='orange');\n",
    "\n",
    "p_val = low_prob + high_prob            \n",
    "print(p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> if the p-value less than type I error=0.05. it would indicate a low probability of assuming that the null hypothesis is true. I got the p-value for both directions because the alternative hypothesis is two sided and that mean have both negative value or positive can applay.\n",
    "\n",
    "\n",
    "> the p-value is above 0.05 which means I fail to reject the null hypothsis so I have evidence that old page equal in converted rate with the new page.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l. I would also use a built-in to calculate the number of conversions for each page, as well as the number of individuals who received each page. where `n_old` and `n_new` refer the the number of rows associated with the old page and new pages, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute number of conversion for old page and new page\n",
    "convert_old = df2.query('landing_page == \"old_page\"')['converted'].sum()\n",
    "convert_new = df2.query('landing_page == \"new_page\"')['converted'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m. Now use `stats.proportions_ztest` to compute your test statistic and p-value.  [Here](https://docs.w3cub.com/statsmodels/generated/statsmodels.stats.proportion.proportions_ztest/) is a helpful link on using the built in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the computed z test statistic is 1.3109241984234394\n",
      "the p-value is  0.18988337448195103\n"
     ]
    }
   ],
   "source": [
    "#using stats.proportions_ztest to compute Z-test and p-value\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "number_of_success = np.array([convert_old,convert_new])\n",
    "total_sample_size = np.array([n_old,n_new])\n",
    "\n",
    "(stat,pval) = proportions_ztest(number_of_success, total_sample_size, alternative='two-sided')\n",
    "print(\"the computed z test statistic is\", stat)\n",
    "print(\"the p-value is \",pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.904902082204761"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute the significance of z-score\n",
    "from scipy.stats import norm\n",
    "\n",
    "norm.cdf(1.31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6448536269514722"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute crtical values at 95% confidence level\n",
    "norm.ppf(1-.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> the z-score I've computed means the difference between the test(the difference between conversion rates) and the null hypothesis is 1.31\n",
    "standard deviation above the mean. with type I error = 0.05 and confidence level 95% the critical values are 1.96, which means z score less than the critical value so I havn't evidence to reject the null hypothesis and that mean the old page is equal the new page in converasion rates\n",
    "\n",
    ">the p-value here is 0.189 and it is greater than alpha so I fail to reject the null hypothesis which is mean the difference between the means is not statistically significant and the old page is equal the new page in converasion rates\n",
    "\n",
    "> this p-value I've got from z test equal the previous p-value = 0.1942\n",
    " so the z-test appears to agree with the previous findings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regression'></a>\n",
    "### Part III - A regression approach\n",
    "\n",
    "`1.` In this final part,I will fit model is attempting to predict whether a user will convert depending on their received page.\n",
    "and see that if the result that achieved in the A/B test in Part II above can also be achieved by performing regression.<br><br> \n",
    "\n",
    "a. Since each row is either a conversion or no conversion,I would perform Logistic Regression in this case because the the response variable is categorical variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. So I'll use **statsmodels** to fit the logistic regression model to see if there is a significant difference in conversion based on which page a customer receives. However, I'll create in df2 a column for the intercept, and I'll create a dummy variable column for which page each user received that would be an **ab_page** column, which is 1 when an individual receives the **treatment** and 0 if **control** to predict whether or not an individual converts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>old_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  ab_page  old_page  \n",
       "0          1        0         1  \n",
       "1          1        0         1  \n",
       "2          1        1         0  \n",
       "3          1        1         0  \n",
       "4          1        0         1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a column for the intercept\n",
    "df2['intercept']= 1\n",
    "\n",
    "#create dummy variable column for which page each user received\n",
    "df2[['ab_page','old_page']] = pd.get_dummies(df2['landing_page'])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop old page and make it basline \n",
    "df2 = df2.drop('old_page', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34808</th>\n",
       "      <td>747677</td>\n",
       "      <td>2017-01-22 03:05:12.852955</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id                   timestamp      group landing_page  converted  \\\n",
       "34808   747677  2017-01-22 03:05:12.852955  treatment     new_page          1   \n",
       "\n",
       "       intercept  ab_page  \n",
       "34808          1        1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366118\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>converted</td>          <td>AIC:</td>        <td>212780.3502</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-03-02 22:01</td>       <td>BIC:</td>        <td>212801.5095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>290584</td>       <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>1</td>            <td>LL-Null:</td>      <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>290582</td>        <td>LLR p-value:</td>      <td>0.18988</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>      <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-1.9888</td>  <td>0.0081</td>  <td>-246.6690</td> <td>0.0000</td> <td>-2.0046</td> <td>-1.9730</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>-0.0150</td>  <td>0.0114</td>   <td>-1.3109</td>  <td>0.1899</td> <td>-0.0374</td> <td>0.0074</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.000      \n",
       "Dependent Variable: converted        AIC:              212780.3502\n",
       "Date:               2021-03-02 22:01 BIC:              212801.5095\n",
       "No. Observations:   290584           Log-Likelihood:   -1.0639e+05\n",
       "Df Model:           1                LL-Null:          -1.0639e+05\n",
       "Df Residuals:       290582           LLR p-value:      0.18988    \n",
       "Converged:          1.0000           Scale:            1.0000     \n",
       "No. Iterations:     6.0000                                        \n",
       "-------------------------------------------------------------------\n",
       "              Coef.   Std.Err.      z      P>|z|    [0.025   0.975]\n",
       "-------------------------------------------------------------------\n",
       "intercept    -1.9888    0.0081  -246.6690  0.0000  -2.0046  -1.9730\n",
       "ab_page      -0.0150    0.0114    -1.3109  0.1899  -0.0374   0.0074\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a logistic model and fit it with the dummy variable and intercept \n",
    "log_model = sm.Logit(df2['converted'], df2[['intercept','ab_page']])\n",
    "results = log_model.fit()\n",
    "# show the summary of the model \n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is attempting to predict whether a user will convert depending on the page that customer received. The null hypothesis is that when ab_page = 1, converted = 0; the alternative hypothesis is that when ab_page = 1, converted is more likely to be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9851119396030626"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-0.0150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.015113064615719"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/np.exp(-0.0150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**the p-value associated with ab_page is 0.1899 that mean p-value > alpha which means I'll fail to reject the null hypothesis \n",
    "which is similar to the previous values, but slightly smaller**.\n",
    "\n",
    "\n",
    ">  from this model interpret that for every one not recieved the new page , the converted is 1.015 times as likely to happen and this not has much impact on increasing the conversion rates so it will be cost for not more icreasing in conversion rates\n",
    "\n",
    "> and the p-value not differ much from the value I found it in a/b testing where we still reject to fail the null hypothesis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, it does not appear that the treatment or control page has much impact on whether a user converts. Therefore, it is probably a good idea to add an effect based on which country a user lives in.to see if  whether effected in predicting conversion.\n",
    "\n",
    "thus I'll create dummy variables for these country columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It is important to be when selecting factors to make sure the factors are not in and of themselves collinear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. Now along with testing if the conversion rate changes for different pages, also add an effect based on which country a user lives in. You will need to read in the **countries.csv** dataset and merge together your datasets on the appropriate rows.  [Here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.join.html) are the docs for joining tables. \n",
    "\n",
    "Does it appear that country had an impact on conversion?  Don't forget to create dummy variables for these country columns - Provide the statistical output as well as a written response to answer this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>834778</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>928468</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>822059</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>711597</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>710616</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id country\n",
       "0   834778      UK\n",
       "1   928468      US\n",
       "2   822059      UK\n",
       "3   711597      UK\n",
       "4   710616      UK"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the data of country a user live in\n",
    "country = pd.read_csv('countries.csv')\n",
    "country.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US    203619\n",
       "UK     72466\n",
       "CA     14499\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the unique values in country column\n",
    "country.country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  ab_page country  \n",
       "0          1        0      US  \n",
       "1          1        0      US  \n",
       "2          1        1      US  \n",
       "3          1        1      US  \n",
       "4          1        0      US  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merage the country dataframe with the orignal dataframe\n",
    "df3 = df2.merge(country, on='user_id', how='left')\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>country</th>\n",
       "      <th>US</th>\n",
       "      <th>UK</th>\n",
       "      <th>CA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  ab_page country  US  UK  CA  \n",
       "0          1        0      US   0   0   1  \n",
       "1          1        0      US   0   0   1  \n",
       "2          1        1      US   0   0   1  \n",
       "3          1        1      US   0   0   1  \n",
       "4          1        0      US   0   0   1  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make dummies varaible for countries\n",
    "df3[['US','UK', 'CA']]= pd.get_dummies(df3['country'])\n",
    "\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366113\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>converted</td>          <td>AIC:</td>        <td>212781.1253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-03-02 22:01</td>       <td>BIC:</td>        <td>212823.4439</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>290584</td>       <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>3</td>            <td>LL-Null:</td>      <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>290580</td>        <td>LLR p-value:</td>      <td>0.17599</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-2.0300</td>  <td>0.0266</td>  <td>-76.2488</td> <td>0.0000</td> <td>-2.0822</td> <td>-1.9778</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>-0.0149</td>  <td>0.0114</td>   <td>-1.3069</td> <td>0.1912</td> <td>-0.0374</td> <td>0.0075</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA</th>        <td>0.0408</td>   <td>0.0269</td>   <td>1.5161</td>  <td>0.1295</td> <td>-0.0119</td> <td>0.0934</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>0.0506</td>   <td>0.0284</td>   <td>1.7835</td>  <td>0.0745</td> <td>-0.0050</td> <td>0.1063</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.000      \n",
       "Dependent Variable: converted        AIC:              212781.1253\n",
       "Date:               2021-03-02 22:01 BIC:              212823.4439\n",
       "No. Observations:   290584           Log-Likelihood:   -1.0639e+05\n",
       "Df Model:           3                LL-Null:          -1.0639e+05\n",
       "Df Residuals:       290580           LLR p-value:      0.17599    \n",
       "Converged:          1.0000           Scale:            1.0000     \n",
       "No. Iterations:     6.0000                                        \n",
       "-------------------------------------------------------------------\n",
       "               Coef.   Std.Err.     z      P>|z|    [0.025   0.975]\n",
       "-------------------------------------------------------------------\n",
       "intercept     -2.0300    0.0266  -76.2488  0.0000  -2.0822  -1.9778\n",
       "ab_page       -0.0149    0.0114   -1.3069  0.1912  -0.0374   0.0075\n",
       "CA             0.0408    0.0269    1.5161  0.1295  -0.0119   0.0934\n",
       "UK             0.0506    0.0284    1.7835  0.0745  -0.0050   0.1063\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make logistic model to predict the converted using CA and old page as baseline\n",
    "\n",
    "log_model_2= sm.Logit(df3['converted'], df3[['intercept','ab_page' , 'CA','UK']])\n",
    "results= log_model_2.fit()\n",
    "results.summary2()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the p-values above, it also does not appear as though country has a significant impact on conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. Though you have now looked at the individual factors of country and page on conversion, I would now like to look at an interaction between page and country to see if there significant effects on conversion.  Create the necessary additional columns, and fit the new model.  \n",
    "\n",
    "Provide the summary results, and conclusions based on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an interaction variables between page and country to see if there significant effects on conversion\n",
    "df3['CA_page'] = df3['CA']*df3['ab_page']\n",
    "df3['UK_page'] = df3['UK']*df3['ab_page']\n",
    "df3['US_page'] = df3['US']*df3['ab_page']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366117\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>converted</td>          <td>AIC:</td>        <td>212781.7674</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-03-02 22:01</td>       <td>BIC:</td>        <td>212813.5064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>290584</td>       <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>2</td>            <td>LL-Null:</td>      <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>290581</td>        <td>LLR p-value:</td>      <td>0.31643</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>      <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-1.9926</td>  <td>0.0079</td>  <td>-252.9104</td> <td>0.0000</td> <td>-2.0081</td> <td>-1.9772</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA_page</th>   <td>-0.0144</td>  <td>0.0125</td>   <td>-1.1548</td>  <td>0.2482</td> <td>-0.0389</td> <td>0.0101</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK_page</th>   <td>0.0112</td>   <td>0.0179</td>   <td>0.6256</td>   <td>0.5316</td> <td>-0.0240</td> <td>0.0464</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.000      \n",
       "Dependent Variable: converted        AIC:              212781.7674\n",
       "Date:               2021-03-02 22:01 BIC:              212813.5064\n",
       "No. Observations:   290584           Log-Likelihood:   -1.0639e+05\n",
       "Df Model:           2                LL-Null:          -1.0639e+05\n",
       "Df Residuals:       290581           LLR p-value:      0.31643    \n",
       "Converged:          1.0000           Scale:            1.0000     \n",
       "No. Iterations:     6.0000                                        \n",
       "-------------------------------------------------------------------\n",
       "              Coef.   Std.Err.      z      P>|z|    [0.025   0.975]\n",
       "-------------------------------------------------------------------\n",
       "intercept    -1.9926    0.0079  -252.9104  0.0000  -2.0081  -1.9772\n",
       "CA_page      -0.0144    0.0125    -1.1548  0.2482  -0.0389   0.0101\n",
       "UK_page       0.0112    0.0179     0.6256  0.5316  -0.0240   0.0464\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make logistic model to predict the converted using an interaction variables between page and country \n",
    "\n",
    "log_model_3= sm.Logit(df3['converted'], df3[['intercept','CA_page','UK_page']])\n",
    "results= log_model_3.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept    0.136338\n",
       "CA_page      0.985679\n",
       "UK_page      1.011292\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exponentiated the CV to inteprete the result\n",
    "np.exp(results.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept    7.334699\n",
       "CA_page      1.014530\n",
       "UK_page      0.988834\n",
       "dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/np.exp(results.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Interpreting \n",
    " \n",
    "**in this model above show** \n",
    "\n",
    "      there is negative relation between ab_page and converted meaning that being a new page           \n",
    "      decreases the liklihood of converted by 1.02 times\n",
    "      \n",
    "      also there is a negative relation between Uk and converted that mean being from \n",
    "      Us decrease converted rate by 1.005\n",
    "      \n",
    "      and there is a negative relation between Us and converted rate that mean beaing from\n",
    "      Uk increase the liklihood of convrted rate by 1.017\n",
    "      \n",
    "**that mean the user country and the new page that user receive doesn't affect in conversion rate**\n",
    "\n",
    "**look at the interaction variables between page and country**\n",
    "\n",
    "     there is a negative relation between US_new_page and converted that mean being from US and received the new page decrease the liklihood of converted rate by 1.04\n",
    "     \n",
    "     and I have positive relation between UK_new_page and converted that mean being from UK and received the new page increase the liklihood of converted rate by 1.03 \n",
    "     \n",
    "     \n",
    "#### Whereas all reuslts not high enough to affect in converted rated , that's mean the page and country dataset are not a good fit to predit converted rate So I will train and test the data set to prevent or minimize overfitting.    \n",
    "\n",
    "      \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'Analyze_ab_test_results_notebook.ipynb'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
